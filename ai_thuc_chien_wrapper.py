"""
AI Th·ª±c Chi·∫øn API Wrapper
=========================


Wrapper class ho√†n ch·ªânh cho AI Th·ª±c Chi·∫øn API Gateway
T√≠ch h·ª£p t·∫•t c·∫£ tricks v√† best practices t·ª´ documentation


Author: AI Th·ª±c Chi·∫øn Competition
Version: 1.0.0
"""


import requests
import base64
import time
import random
import json
from typing import List, Dict, Optional, Union, Tuple
from pathlib import Path
import io




class AIThucChienAPI:
    """
    Wrapper class ch√≠nh cho AI Th·ª±c Chi·∫øn API


    Usage:
        api = AIThucChienAPI(api_key="your_api_key")
        response = api.generate_text("Hello world")
    """


    def __init__(self, api_key: str, base_url: str = "https://api.thucchien.ai"):
        """
        Kh·ªüi t·∫°o API client


        Args:
            api_key: API key t·ª´ AI Th·ª±c Chi·∫øn
            base_url: Base URL c·ªßa API (default: https://api.thucchien.ai)
        """
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.gemini_headers = {
            "x-goog-api-key": api_key,
            "Content-Type": "application/json"
        }


    # =============================================
    # PH·∫¶N 1: C√ÅC H√ÄM C∆† B·∫¢N (Basic Functions)
    # =============================================


    def generate_text(
        self,
        prompt: str,
        model: str = "gemini-2.5-pro",
        temperature: float = 1.0,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict:
        """
        Sinh vƒÉn b·∫£n t·ª´ prompt


        Args:
            prompt: N·ªôi dung prompt
            model: T√™n model (gemini-2.5-pro, gemini-2.5-flash)
            temperature: ƒê·ªô ng·∫´u nhi√™n (0-2)
            max_tokens: S·ªë tokens t·ªëi ƒëa


        Returns:
            Dict ch·ª©a response t·ª´ API
        """
        url = f"{self.base_url}/chat/completions"


        data = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature
        }


        if max_tokens:
            data["max_tokens"] = max_tokens


        data.update(kwargs)


        response = requests.post(url, headers=self.headers, json=data)
        response.raise_for_status()
        return response.json()


    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "gemini-2.5-pro",
        temperature: float = 1.0,
        **kwargs
    ) -> Dict:
        """
        T·∫°o chat completion v·ªõi history messages


        Args:
            messages: List c√°c messages theo format OpenAI
            model: T√™n model
            temperature: ƒê·ªô ng·∫´u nhi√™n


        Returns:
            Dict ch·ª©a response
        """
        url = f"{self.base_url}/chat/completions"


        data = {
            "model": model,
            "messages": messages,
            "temperature": temperature
        }
        data.update(kwargs)


        response = requests.post(url, headers=self.headers, json=data)
        response.raise_for_status()
        return response.json()


    def generate_image(
        self,
        prompt: str,
        model: str = "imagen-4",
        n: int = 1,
        aspect_ratio: str = "1:1",
        **kwargs
    ) -> List[str]:
        """
        Sinh h√¨nh ·∫£nh t·ª´ prompt (tr·∫£ v·ªÅ list base64 data URLs)


        Args:
            prompt: M√¥ t·∫£ h√¨nh ·∫£nh
            model: T√™n model (imagen-4)
            n: S·ªë l∆∞·ª£ng ·∫£nh c·∫ßn t·∫°o (1-4)
            aspect_ratio: T·ª∑ l·ªá khung h√¨nh (1:1, 3:4, 4:3, 16:9, 9:16)


        Returns:
            List c√°c data URL c·ªßa ·∫£nh (data:image/png;base64,...)
        """
        # Th√™m random seed ƒë·ªÉ tr√°nh cache (TRICK t·ª´ docs)
        prompt_with_seed = f"{prompt} {random.randint(1, 10000)}"


        url = f"{self.base_url}/images/generations"


        data = {
            "model": model,
            "prompt": prompt_with_seed,
            "n": n,
            "aspect_ratio": aspect_ratio
        }
        data.update(kwargs)


        response = requests.post(url, headers=self.headers, json=data)
        response.raise_for_status()


        result = response.json()
        images = []
        for item in result.get('data', []):
            b64_data = item.get('b64_json')
            if b64_data:
                # Return as data URL format
                images.append(f"data:image/png;base64,{b64_data}")


        return images


    def generate_image_chat(
        self,
        prompt: str,
        model: str = "gemini-2.5-flash-image-preview",
        messages: Optional[List[Dict]] = None
    ) -> str:
        """
        Sinh h√¨nh ·∫£nh qua chat endpoint (multimodal)
        H·ªó tr·ª£ consistent character generation


        Args:
            prompt: M√¥ t·∫£ h√¨nh ·∫£nh
            model: Model multimodal
            messages: History messages ƒë·ªÉ maintain consistency


        Returns:
            Data URL c·ªßa ·∫£nh (data:image/png;base64,...)
        """
        url = f"{self.base_url}/chat/completions"


        if messages is None:
            messages = []


        messages.append({"role": "user", "content": prompt})


        data = {
            "model": model,
            "messages": messages,
            "modalities": ["image"]
        }


        response = requests.post(url, headers=self.headers, json=data)
        response.raise_for_status()


        result = response.json()
        image_url = result['choices'][0]['message']['images'][0]['image_url']['url']


        return image_url


    def text_to_speech(
        self,
        text: str,
        model: str = "gemini-2.5-flash-preview-tts",
        voice: str = "Zephyr"
    ) -> bytes:
        """
        Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i


        Args:
            text: VƒÉn b·∫£n c·∫ßn chuy·ªÉn
            model: Model TTS
            voice: Gi·ªçng n√≥i (Zephyr, Puck, Charon, Kore, ...)


        Returns:
            Bytes c·ªßa file √¢m thanh
        """
        url = f"{self.base_url}/audio/speech"


        data = {
            "model": model,
            "input": text,
            "voice": voice
        }


        response = requests.post(url, headers=self.headers, json=data, stream=True)
        response.raise_for_status()


        return response.content


    def text_to_speech_gemini(
        self,
        text: str,
        model: str = "gemini-2.5-flash-preview-tts",
        multi_speaker: bool = False,
        speaker_configs: Optional[List[Dict]] = None
    ) -> bytes:
        """
        Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i v·ªõi Gemini API (h·ªó tr·ª£ multi-speaker)


        Args:
            text: VƒÉn b·∫£n c·∫ßn chuy·ªÉn
            model: Model TTS
            multi_speaker: C√≥ ph·∫£i multi-speaker kh√¥ng
            speaker_configs: Danh s√°ch config cho t·ª´ng speaker
                            Format: [{"speaker": "John", "voice": "Puck"}, ...]


        Returns:
            Bytes c·ªßa file √¢m thanh
        """
        url = f"{self.base_url}/gemini/v1beta/models/{model}:generateContent"


        data = {
            "contents": [{
                "parts": [{"text": text}]
            }],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": {}
            }
        }


        if multi_speaker and speaker_configs:
            # Multi-speaker configuration
            speaker_voice_configs = []
            for config in speaker_configs:
                speaker_voice_configs.append({
                    "speaker": config["speaker"],
                    "voiceConfig": {
                        "prebuiltVoiceConfig": {
                            "voiceName": config["voice"]
                        }
                    }
                })


            data["generationConfig"]["speechConfig"]["multiSpeakerVoiceConfig"] = {
                "speakerVoiceConfigs": speaker_voice_configs
            }
        else:
            # Single speaker configuration
            voice = speaker_configs[0]["voice"] if speaker_configs else "Kore"
            data["generationConfig"]["speechConfig"]["voiceConfig"] = {
                "prebuiltVoiceConfig": {
                    "voiceName": voice
                }
            }


        response = requests.post(url, headers=self.gemini_headers, json=data)
        response.raise_for_status()


        result = response.json()


        # Extract audio data from response
        audio_b64 = result["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]
        return base64.b64decode(audio_b64)


    def check_spending(self) -> Dict:
        """
        Ki·ªÉm tra chi ti√™u API key


        Returns:
            Dict ch·ª©a th√¥ng tin chi ti√™u
        """
        url = f"{self.base_url}/key/info"


        response = requests.get(url, headers=self.headers)
        response.raise_for_status()


        return response.json()


    # =============================================
    # PH·∫¶N 2: VIDEO GENERATION (Async 3-step process)
    # =============================================


    def start_video_generation(
        self,
        prompt: str,
        model: str = "veo-3.0-generate-001",
        aspect_ratio: str = "16:9",
        resolution: str = "720p",
        image_base64: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        B∆∞·ªõc 1: B·∫Øt ƒë·∫ßu t·∫°o video (async)


        Args:
            prompt: M√¥ t·∫£ video
            model: Model video (veo-3.0-generate-001, veo-3.0-fast-generate-001, veo-2.0-generate-001)
            aspect_ratio: T·ª∑ l·ªá (16:9 ho·∫∑c 9:16)
            resolution: ƒê·ªô ph√¢n gi·∫£i (720p ho·∫∑c 1080p)
            image_base64: ·∫¢nh ƒë·∫ßu v√†o (base64) cho image-to-video


        Returns:
            operation_name ƒë·ªÉ tracking
        """
        url = f"{self.base_url}/gemini/v1beta/models/{model}:predictLongRunning"


        instance = {"prompt": prompt}


        if image_base64:
            instance["image"] = {
                "bytesBase64Encoded": image_base64,
                "mimeType": "image/png"
            }


        data = {
            "instances": [instance],
            "parameters": {
                "aspectRatio": aspect_ratio,
                "resolution": resolution
            }
        }


        # Add extra parameters
        data["parameters"].update(kwargs)


        response = requests.post(url, headers=self.gemini_headers, json=data)
        response.raise_for_status()


        result = response.json()
        return result.get("name")


    def check_video_status(self, operation_name: str) -> Tuple[bool, Optional[str]]:
        """
        B∆∞·ªõc 2: Ki·ªÉm tra tr·∫°ng th√°i video


        Args:
            operation_name: Name t·ª´ b∆∞·ªõc 1


        Returns:
            (is_done, video_uri)
        """
        url = f"{self.base_url}/gemini/v1beta/{operation_name}"


        response = requests.get(url, headers=self.gemini_headers)
        response.raise_for_status()


        result = response.json()
        is_done = result.get("done", False)


        video_uri = None
        if is_done and "response" in result:
            try:
                video_uri = result["response"]["generateVideoResponse"]["generatedSamples"][0]["video"]["uri"]
            except (KeyError, IndexError):
                pass


        return is_done, video_uri


    def download_video(self, video_uri: str) -> bytes:
        """
        B∆∞·ªõc 3: T·∫£i video v·ªÅ


        Args:
            video_uri: URI t·ª´ b∆∞·ªõc 2


        Returns:
            Bytes c·ªßa video
        """
        # Extract video_id from URI
        # URI format: https://generativelanguage.googleapis.com/v1beta/files/{video_id}:download?alt=media
        video_id = video_uri.split('/files/')[1].split(':')[0]


        url = f"{self.base_url}/gemini/download/v1beta/files/{video_id}:download?alt=media"


        response = requests.get(url, headers=self.gemini_headers, stream=True)
        response.raise_for_status()


        return response.content


    # =============================================
    # PH·∫¶N 3: C√ÅC H√ÄM N√ÇNG CAO (Advanced Functions with Tricks)
    # =============================================


    def generate_video_complete(
        self,
        prompt: str,
        model: str = "veo-3.0-generate-001",
        max_wait_time: int = 600,
        poll_interval: int = 10,
        **kwargs
    ) -> bytes:
        """
        T·∫°o video ho√†n ch·ªânh (auto polling)


        Args:
            prompt: M√¥ t·∫£ video
            model: Model video
            max_wait_time: Th·ªùi gian ch·ªù t·ªëi ƒëa (gi√¢y)
            poll_interval: Kho·∫£ng th·ªùi gian gi·ªØa c√°c l·∫ßn check (gi√¢y)


        Returns:
            Bytes c·ªßa video
        """
        print(f"üé¨ B·∫Øt ƒë·∫ßu t·∫°o video: {prompt[:50]}...")


        # B∆∞·ªõc 1: Start
        operation_name = self.start_video_generation(prompt, model, **kwargs)
        print(f"‚úÖ ƒê√£ b·∫Øt ƒë·∫ßu: {operation_name}")


        # B∆∞·ªõc 2: Poll until done
        start_time = time.time()
        current_interval = poll_interval


        while time.time() - start_time < max_wait_time:
            print(f"‚è≥ ƒêang ki·ªÉm tra... ({int(time.time() - start_time)}s)")


            is_done, video_uri = self.check_video_status(operation_name)


            if is_done and video_uri:
                print("üéâ Video ƒë√£ ho√†n th√†nh!")
                # B∆∞·ªõc 3: Download
                video_bytes = self.download_video(video_uri)
                print(f"üì• ƒê√£ t·∫£i xong: {len(video_bytes)} bytes")
                return video_bytes


            time.sleep(current_interval)
            # Exponential backoff
            current_interval = min(current_interval * 1.2, 30)


        raise TimeoutError(f"Timeout after {max_wait_time} seconds")


    def create_consistent_character_images(
        self,
        character_description: str,
        scenes: List[str],
        model: str = "gemini-2.5-flash-image-preview"
    ) -> List[str]:
        """
        TRICK: T·∫°o nhi·ªÅu ·∫£nh v·ªõi nh√¢n v·∫≠t nh·∫•t qu√°n
        Ph∆∞∆°ng ph√°p: Gh√©p character description v√†o m·ªói scene prompt


        Args:
            character_description: M√¥ t·∫£ chi ti·∫øt nh√¢n v·∫≠t
            scenes: List c√°c scene kh√°c nhau
            model: Model multimodal


        Returns:
            List data URLs c·ªßa c√°c ·∫£nh
        """
        images = []


        # ·∫¢nh ƒë·∫ßu ti√™n: m√¥ t·∫£ ƒë·∫ßy ƒë·ªß
        print(f"üé® T·∫°o ·∫£nh tham chi·∫øu: {character_description[:50]}...")
        first_image = self.generate_image_chat(character_description, model)
        images.append(first_image)


        # C√°c ·∫£nh ti·∫øp theo: Gh√©p character description + scene description
        for i, scene in enumerate(scenes):
            print(f"üé® T·∫°o ·∫£nh {i+2}/{len(scenes)+1}: {scene[:50]}...")


            # TRICK: Gh√©p character v√†o scene ƒë·ªÉ gi·ªØ nh·∫•t qu√°n
            combined_prompt = f"{character_description}, {scene}"


            image = self.generate_image_chat(combined_prompt, model)
            images.append(image)


        print(f"‚úÖ Ho√†n th√†nh {len(images)} ·∫£nh v·ªõi c√πng nh√¢n v·∫≠t!")
        return images


    def create_vietnamese_text_image(
        self,
        background_prompt: str,
        vietnamese_text: str,
        text_color: str = "yellow",
        model: str = "gemini-2.5-flash-image-preview"
    ) -> bytes:
        """
        TRICK: T·∫°o ·∫£nh c√≥ ch·ªØ ti·∫øng Vi·ªát kh√¥ng b·ªã l·ªói font
        1. T·∫°o ·∫£nh n·ªÅn kh√¥ng c√≥ ch·ªØ
        2. T·∫°o ·∫£nh ch·ªØ ri√™ng
        3. D√πng AI merge 2 ·∫£nh


        Args:
            background_prompt: M√¥ t·∫£ ·∫£nh n·ªÅn
            vietnamese_text: Ch·ªØ ti·∫øng Vi·ªát c·∫ßn th√™m
            text_color: M√†u ch·ªØ
            model: Model multimodal


        Returns:
            Bytes c·ªßa ·∫£nh ho√†n ch·ªânh
        """
        # B∆∞·ªõc 1: T·∫°o ·∫£nh n·ªÅn kh√¥ng c√≥ ch·ªØ
        print("üé® B∆∞·ªõc 1: T·∫°o ·∫£nh n·ªÅn...")
        background_prompt_no_text = f"{background_prompt}. Do not include any text. Leave a clear, empty space for the title text."
        background_img = self.generate_image_chat(background_prompt_no_text, model)


        # B∆∞·ªõc 2: Ng∆∞·ªùi d√πng t·ª± t·∫°o ·∫£nh ch·ªØ b·∫±ng tool (Canva, Photoshop...)
        # ·ªû ƒë√¢y ch·ªâ h∆∞·ªõng d·∫´n
        print(f"üìù B∆∞·ªõc 2: T·∫°o ·∫£nh ch·ªØ '{vietnamese_text}' b·∫±ng Canva/Photoshop")
        print("   - N·ªÅn tr·∫Øng")
        print("   - Font ƒë·∫πp")
        print("   - L∆∞u th√†nh PNG/JPG")
        print("   - Chuy·ªÉn sang base64 v√† truy·ªÅn v√†o merge_vietnamese_text_to_image()")


        return background_img


    def merge_vietnamese_text_to_image(
        self,
        background_image_base64: str,
        text_image_base64: str,
        placement_instruction: str = "Place it in a visually fitting position",
        model: str = "gemini-2.5-flash-image-preview"
    ) -> bytes:
        """
        TRICK: Merge ch·ªØ ti·∫øng Vi·ªát v√†o ·∫£nh n·ªÅn b·∫±ng AI


        Args:
            background_image_base64: Base64 c·ªßa ·∫£nh n·ªÅn
            text_image_base64: Base64 c·ªßa ·∫£nh ch·ªØ
            placement_instruction: H∆∞·ªõng d·∫´n ƒë·∫∑t ch·ªØ
            model: Model multimodal


        Returns:
            Bytes c·ªßa ·∫£nh ƒë√£ merge
        """
        url = f"{self.base_url}/gemini/v1beta/models/{model}:generateContent"


        data = {
            "contents": [{
                "parts": [
                    {
                        "inline_data": {
                            "mime_type": "image/png",
                            "data": background_image_base64
                        }
                    },
                    {
                        "inline_data": {
                            "mime_type": "image/png",
                            "data": text_image_base64
                        }
                    },
                    {
                        "text": f"Add the text from the second image onto the first image. {placement_instruction}"
                    }
                ]
            }],
            "generationConfig": {
                "imageConfig": {
                    "aspectRatio": "1:1"
                }
            }
        }


        response = requests.post(url, headers=self.gemini_headers, json=data)
        response.raise_for_status()


        result = response.json()
        image_data = result['candidates'][0]['content']['parts'][0]['inlineData']['data']


        return base64.b64decode(image_data)


    def create_comic_consistent(
        self,
        title: str,
        character_description: str,
        panels: List[Dict[str, str]],
        model: str = "gemini-2.5-flash-image-preview"
    ) -> List[bytes]:
        """
        T·∫°o truy·ªán tranh v·ªõi nh√¢n v·∫≠t nh·∫•t qu√°n


        Args:
            title: Ti√™u ƒë·ªÅ truy·ªán
            character_description: M√¥ t·∫£ nh√¢n v·∫≠t chi ti·∫øt
            panels: List c√°c panel, m·ªói panel l√† dict {"scene": "...", "dialogue": "..."}
            model: Model multimodal


        Returns:
            List bytes c·ªßa c√°c trang truy·ªán
        """
        print(f"üìñ T·∫°o truy·ªán tranh: {title}")


        # T·∫°o cover page
        cover_prompt = f"Comic book cover titled '{title}'. {character_description}. Semi-realistic manga style, A4 vertical."
        print("üé® T·∫°o trang b√¨a...")
        cover_img = self.generate_image_chat(cover_prompt, model)


        # T·∫°o c√°c panel v·ªõi nh√¢n v·∫≠t nh·∫•t qu√°n
        panel_scenes = [p["scene"] for p in panels]
        panel_images = self.create_consistent_character_images(
            character_description,
            panel_scenes,
            model
        )


        print(f"‚úÖ Ho√†n th√†nh truy·ªán tranh {len(panel_images) + 1} trang!")
        return [cover_img] + panel_images


    def create_news_video_with_mc(
        self,
        news_content: str,
        mc_description: str = "A professional Vietnamese female news anchor, 30s, wearing formal attire",
        duration: int = 80,
        model: str = "veo-3.0-generate-001"
    ) -> bytes:
        """
        TRICK: T·∫°o video b·∫£n tin c√≥ MC ·∫£o
        1. T·∫°o ·∫£nh MC nh·∫•t qu√°n
        2. T·∫°o script ƒë·ªçc tin
        3. T·∫°o TTS cho MC
        4. T·∫°o video t·ª´ ·∫£nh MC + prompt
        5. User t·ª± gh√©p video + audio b·∫±ng tool


        Args:
            news_content: N·ªôi dung tin t·ª©c
            mc_description: M√¥ t·∫£ MC
            duration: Th·ªùi l∆∞·ª£ng video
            model: Model video


        Returns:
            Bytes c·ªßa video MC (ch∆∞a c√≥ audio)
        """
        print("üì∫ T·∫°o video b·∫£n tin v·ªõi MC ·∫£o...")


        # B∆∞·ªõc 1: T·∫°o ·∫£nh MC
        print("üé® T·∫°o h√¨nh ·∫£nh MC...")
        mc_image = self.generate_image_chat(mc_description)
        mc_image_base64 = base64.b64encode(mc_image).decode('utf-8')


        # B∆∞·ªõc 2: T·∫°o script
        print("üìù T·∫°o script...")
        script_prompt = f"Vi·∫øt script b·∫£n tin truy·ªÅn h√¨nh chuy√™n nghi·ªáp v·ªÅ: {news_content}. Th·ªùi l∆∞·ª£ng {duration} gi√¢y. VƒÉn phong trang tr·ªçng, d·ªÖ hi·ªÉu."
        script_response = self.generate_text(script_prompt)
        script = script_response['choices'][0]['message']['content']


        # B∆∞·ªõc 3: T·∫°o TTS
        print("üéôÔ∏è T·∫°o gi·ªçng ƒë·ªçc...")
        audio = self.text_to_speech(script, voice="Kore")  # Gi·ªçng n·ªØ chuy√™n nghi·ªáp


        # L∆∞u audio ƒë·ªÉ user merge sau
        with open("mc_voice.mp3", "wb") as f:
            f.write(audio)
        print("üíæ ƒê√£ l∆∞u mc_voice.mp3")


        # B∆∞·ªõc 4: T·∫°o video MC
        print("üé¨ T·∫°o video MC...")
        video_prompt = f"A professional news anchor is presenting the news on television. {mc_description}. She is speaking confidently to the camera with professional hand gestures. Studio lighting, TV broadcast quality."


        video = self.generate_video_complete(
            video_prompt,
            model=model,
            image_base64=mc_image_base64
        )


        print("‚úÖ Ho√†n th√†nh! D√πng Premiere/FFmpeg ƒë·ªÉ gh√©p video + mc_voice.mp3")
        return video


    def analyze_and_summarize_web_content(
        self,
        topic: str,
        web_sources: List[str],
        model: str = "gemini-2.5-pro"
    ) -> str:
        """
        Ph√¢n t√≠ch v√† t·ªïng h·ª£p n·ªôi dung t·ª´ web
        (User c·∫ßn crawl data tr∆∞·ªõc, h√†m n√†y ch·ªâ summarize)


        Args:
            topic: Ch·ªß ƒë·ªÅ c·∫ßn ph√¢n t√≠ch
            web_sources: List n·ªôi dung ƒë√£ crawl t·ª´ web
            model: Model LLM


        Returns:
            B·∫£n t·ªïng h·ª£p
        """
        combined_content = "\n\n---\n\n".join(web_sources)


        prompt = f"""
        Ph√¢n t√≠ch v√† t·ªïng h·ª£p th√¥ng tin v·ªÅ ch·ªß ƒë·ªÅ: {topic}


        D·ªØ li·ªáu t·ª´ c√°c ngu·ªìn:
        {combined_content}


        Y√™u c·∫ßu:
        1. T·ªïng h·ª£p c√°c th√¥ng tin ch√≠nh
        2. Ph√¢n t√≠ch c√°c ƒëi·ªÉm n·ªïi b·∫≠t
        3. ƒê∆∞a ra k·∫øt lu·∫≠n


        Tr√¨nh b√†y theo format markdown.
        """


        response = self.generate_text(prompt, model=model)
        return response['choices'][0]['message']['content']


    # =============================================
    # PH·∫¶N 4: UTILITY FUNCTIONS
    # =============================================


    def save_image(self, image_data: Union[bytes, str], filename: str):
        """
        L∆∞u ·∫£nh ra file


        Args:
            image_data: Bytes ho·∫∑c data URL (data:image/png;base64,...)
            filename: T√™n file ƒë·ªÉ l∆∞u
        """
        if isinstance(image_data, str):
            # Convert data URL to bytes
            if ',' in image_data:
                _, encoded = image_data.split(',', 1)
            else:
                encoded = image_data
            image_bytes = base64.b64decode(encoded)
        else:
            image_bytes = image_data


        with open(filename, 'wb') as f:
            f.write(image_bytes)
        print(f"üíæ ƒê√£ l∆∞u: {filename}")


    def save_audio(self, audio_bytes: bytes, filename: str):
        """L∆∞u audio ra file"""
        with open(filename, 'wb') as f:
            f.write(audio_bytes)
        print(f"üíæ ƒê√£ l∆∞u: {filename}")


    def save_video(self, video_bytes: bytes, filename: str):
        """L∆∞u video ra file"""
        with open(filename, 'wb') as f:
            f.write(video_bytes)
        print(f"üíæ ƒê√£ l∆∞u: {filename}")


    def image_to_base64(self, image_path: str) -> str:
        """Chuy·ªÉn ·∫£nh sang base64"""
        with open(image_path, 'rb') as f:
            return base64.b64encode(f.read()).decode('utf-8')


    def base64_to_image(self, b64_string: str, filename: str):
        """Chuy·ªÉn base64 sang ·∫£nh"""
        image_bytes = base64.b64decode(b64_string)
        self.save_image(image_bytes, filename)




# =============================================
# EXAMPLE USAGE
# =============================================


if __name__ == "__main__":
    # Kh·ªüi t·∫°o API
    api = AIThucChienAPI(api_key="your_api_key_here")


    # Example 1: Text generation
    print("\n=== Example 1: Text Generation ===")
    response = api.generate_text("Gi·∫£i th√≠ch v·ªÅ AI trong 50 t·ª´")
    print(response['choices'][0]['message']['content'])


    # Example 2: Image generation
    print("\n=== Example 2: Image Generation ===")
    images = api.generate_image("A beautiful sunset over the ocean", n=2)
    for i, img in enumerate(images):
        api.save_image(img, f"sunset_{i+1}.png")


    # Example 3: Consistent character comic
    print("\n=== Example 3: Comic with Consistent Character ===")
    comic_pages = api.create_comic_consistent(
        title="Cu·ªôc phi√™u l∆∞u c·ªßa Kenji",
        character_description="A young Japanese detective boy named Kenji, 10 years old, messy black hair, wearing round red glasses and a beige trench coat, anime style",
        panels=[
            {"scene": "He is reading a book in a library", "dialogue": "Hmm, interesting..."},
            {"scene": "He is chasing someone on a busy Tokyo street", "dialogue": "Stop right there!"},
        ]
    )


    # Example 4: Video generation
    print("\n=== Example 4: Video Generation ===")
    video = api.generate_video_complete(
        "A hummingbird flying in slow motion through a garden"
    )
    api.save_video(video, "hummingbird.mp4")


    # Example 5: Check spending
    print("\n=== Example 5: Check Spending ===")
    spending = api.check_spending()
    print(f"ƒê√£ chi ti√™u: ${spending['info']['spend']}")